
from lalr1 import Token
import c.grammar
import lalr1

class Node
  def init(filename)
    self.filename = filename
  end
end

class Macro > Node
  def init(filename, name, args)
    super(filename)
    self.name = name
    self.args = args
  end

  def to_s()
    return "<Macro filename=\"{0}\" name=\"{1}\" args={2}>".format(self.filename, self.name, self.args)
  end
end

class Lexer
  def init(src)
    self.src = src
    self.macros = []
    self.bol? = true # begin of line
    self.pos = 0
    self.filename = ""
  end

  def get_filename()
    m = /# \d+ "(?<filename>.*)"/.match(self.src, self.pos)
    return m == nil ? nil : m.group("filename").to_path()
  end

  def find_next_line()
    if (pos = self.src.find("\n", self.pos)) < 0
      return self.src.size
    end
    return pos + 1
  end

  def skip_to_next_line()
    self.pos = self.find_next_line()
    self.bol? = true
  end

  def get_macro()
    m = /#define (?<name>\w+)(?<args>\([\w\s,]*\))?/.match(self.src, self.pos)
    if m == nil
      return nil
    end
    s = m.group("args")
    args = s != nil ? s.slice(1, -1) : nil
    return Macro.new(self.filename, m.group("name"), args)
  end

  def skip_whitespaces()
    m = /\s+/.match(self.src, self.pos)
    if m == nil
      return
    end
    self.pos = m.end()
    self.bol? = self.src[self.pos - 1] == "\n"
  end

  def match(regexp)
    m = regexp.match(self.src, self.pos)
    if m == nil
      return nil
    end
    self.pos = m.end()
    return m
  end

  def get_next_token()
    self.skip_whitespaces()
    if self.bol? && (self.src.get(self.pos) == "#")
      if (filename = self.get_filename()) != nil
        self.filename = filename
      elif (macro = self.get_macro()) != nil
        self.macros << macro
      end
      self.skip_to_next_line()
      return self.get_next_token()
    end
    self.bol? = false
    if (m = self.match(/\d+/)) != nil
      return Token.new('constant, m.group().to_i())
    elif (m = self.match(/\w[\w\d]*/)) != nil
      name = m.group().to_sym()
      keywords1 = {
        '_Bool, '_Decimal128, '_Decimal32, '_Decimal64, '_Complex,
        '__FUNCTION__, '__PRETTY_FUNCTION__, '__alignof__, '__attribute__,
        '__builtin_choose_expr, '__builtin_offsetof,
        '__builtin_types_compatible_p, '__builtin_va_arg, '__extension__,
        '__func__, '__imag__, '__label__, '__real__, '__thread, 'asm, 'auto,
        'break, 'case, 'char, 'const, 'continue, 'default, 'do, 'double, 'else,
        'enum, 'extern, 'float, 'for, 'goto, 'if, 'inline, 'int, 'long,
        'register, 'restrict, 'return, 'short, 'signed, 'sizeof, 'static,
        'struct, 'switch, 'typeof, 'typedef, 'union, 'unsigned, 'void,
        'volatile, 'while }
      if keywords1.include?(name)
        return Token.new(name)
      end
      keywords2 = {
        '__complex__: '__Complex,
        '__complex: '__Complex,
        '__alignof: '__alignof__,
        '__attribute: '__attribute__,
        '__imag: '__imag__,
        '__real: '__real__,
        '__asm: 'asm,
        '__asm__: 'asm,
        '__const: 'const,
        '__const__: 'const,
        '__inline: 'inline,
        '__inline__: 'inline,
        '__restrict: 'restrict,
        '__restrict__: 'restrict,
        '__signed: 'signed,
        '__signed__: 'signed,
        '__typeof: 'typedef,
        '__typeof__: 'typeof,
        '__volatile: 'volatile,
        '__volatile__: 'volatile }
      if (type = keywords2.get(name)) != nil
        return Token.new(type)
      end
      return Token.new('identifier, name)
    end
    syms = [
      ["&&", 'and_and],
      ["&=", 'and_equal],
      ["&", 'and],
      ["->", 'arrow],
      [":", 'colon],
      [",", 'comma],
      ["/=", 'div_equal],
      ["/", 'div],
      ["...", 'dots],
      [".", 'dot],
      ["==", 'equal_equal],
      ["=", 'equal],
      [">=", 'greater_equal],
      [">", 'greater],
      ["{", 'lbrace],
      ["[", 'lbracket],
      ["<=", 'less_equal],
      ["<", 'less],
      ["(", 'lpar],
      ["<<=", 'lshift_equal],
      ["<<", 'lshift],
      ["-=", 'minus_equal],
      ["--", 'minus_minus],
      ["-", 'minus],
      ["!=", 'not_equal],
      ["!", 'not],
      ["|=", 'or_equal],
      ["||", 'or_or],
      ["|", 'or],
      ["%=", 'percent_equal],
      ["%", 'percent],
      ["+=", 'plus_equal],
      ["++", 'plus_plus],
      ["+", 'plus],
      ["?", 'question],
      ["}", 'rbrace],
      ["]", 'rbracket],
      [")", 'rpar],
      [">>=", 'rshift_equal],
      [">>", 'rshift],
      [";", 'semicolon],
      ["*=", 'star_equal],
      ["*", 'star],
      ["~", 'tilda],
      ["^=", 'xor_equal],
      ["^", 'xor]]
    syms.each() do [entry]
      key = entry[0]
      if self.src.slice(self.pos, key.size) != key
        next
      end
      self.pos += key.size
      return Token.new(entry[1])
    end
    return nil
  end
end

def parse(src)
  lexer = Lexer.new(src)
  nodes = lalr1.parse(c.grammar, lexer.get_next_token)
  return nodes, lexer.macros
end

# vim: tabstop=2 shiftwidth=2 expandtab softtabstop=2
